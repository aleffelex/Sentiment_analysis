{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('tweets-total-csv-3-class-unbalanced.csv', encoding='ISO-8859-1', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataset['tweet'].values\n",
    "classes = dataset['OPINIAO'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessamento(instancia):\n",
    "    #remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    #coloca tudo em minusculo\n",
    "    fraseslimpas = []\n",
    "    for palavras in instancia:\n",
    "        palavras = re.sub(r\"http\\S+\", \"\", palavras).lower().replace(',','').replace('.','').replace(';','').replace('-','').replace(':','').replace('?','')\n",
    "        fraseslimpas.append(palavras)\n",
    "    return (fraseslimpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    #remove stopwords\n",
    "    fraseslimpas = []\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    stopwords.remove('não')\n",
    "    for palavras in instancia:\n",
    "        semstop = [p for p in palavras.split() if p not in stopwords]\n",
    "        fraseslimpas.append((str(semstop)))\n",
    "    return (fraseslimpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SteamingSemStopWords(instancia):\n",
    "    fraseslimpas = []\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    stopwords.remove('não')\n",
    "    for palavras in instancia:\n",
    "        semstop = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwords]\n",
    "        fraseslimpas.append((str(semstop)))\n",
    "    return (fraseslimpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsprocessados = Preprocessamento(tweets)\n",
    "tweetsprocessadossteaming = SteamingSemStopWords(tweetsprocessados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O #BancoDoBrasil já me deixou uma mensagem de parabéns. O 1º.\n",
      "o #bancodobrasil já me deixou uma mensagem de parabéns o 1º\n",
      "['#bancodobrasil', 'deix', 'mens', 'parabém', '1º']\n"
     ]
    }
   ],
   "source": [
    "print(tweets[1])\n",
    "print(tweetsprocessados[1])\n",
    "print(tweetsprocessadossteaming[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweetsprocessadossteaming)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acerto: 72.101090 \n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=50)\n",
    "\n",
    "print('Porcentagem de acerto: %f ' % (metrics.accuracy_score(classes, resultados)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positivo       0.25      0.19      0.22       166\n",
      "    Negativo       0.77      0.92      0.84      1299\n",
      "      Neutro       0.66      0.41      0.50       553\n",
      "\n",
      "    accuracy                           0.72      2018\n",
      "   macro avg       0.56      0.51      0.52      2018\n",
      "weighted avg       0.70      0.72      0.70      2018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opiniao=['Positivo', 'Negativo', 'Neutro']\n",
    "print(metrics.classification_report(classes,resultados,opiniao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |    N         P |\n",
      "         |    e         o |\n",
      "         |    g    N    s |\n",
      "         |    a    e    i |\n",
      "         |    t    u    t |\n",
      "         |    i    t    i |\n",
      "         |    v    r    v |\n",
      "         |    o    o    o |\n",
      "---------+----------------+\n",
      "Negativo |<1198>  67   34 |\n",
      "  Neutro |  266 <225>  62 |\n",
      "Positivo |   86   48  <32>|\n",
      "---------+----------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado = []\n",
    "previsto = []\n",
    "for result in resultados:\n",
    "    previsto.append(result)\n",
    "for classe in classes:\n",
    "    esperado.append(classe)    \n",
    "\n",
    "matriz = ConfusionMatrix(esperado, previsto)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('Dados3.csv', encoding='ISO-8859-1', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@senadorhumberto Duas merdas: PT e Folha de São Paulo.  \\n\\nEm breve não existirá nenhum .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataset2['Text'].values\n",
    "classes = dataset2['Opniao'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsprocessados = Preprocessamento(tweets)\n",
    "tweetsprocessadossteaming = SteamingSemStopWords(tweetsprocessados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@senadorhumberto Duas merdas: PT e Folha de São Paulo.  \n",
      "\n",
      "Em breve não existirá nenhum .\n",
      "@senadorhumberto duas merdas pt e folha de são paulo  \n",
      "\n",
      "em breve não existirá nenhum \n",
      "['@senadorhumbert', 'dua', 'merd', 'pt', 'folh', 'paul', 'brev', 'não', 'existir', 'nenhum']\n"
     ]
    }
   ],
   "source": [
    "print(tweets[1])\n",
    "print(tweetsprocessados[1])\n",
    "print(tweetsprocessadossteaming[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tweets = vectorizer.transform(tweetsprocessadossteaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opniao = modelo.predict(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acerto: 57.142857 \n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem de acerto: %f ' % (metrics.accuracy_score(classes, opniao)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positivo       0.33      0.25      0.29         4\n",
      "    Negativo       0.88      0.50      0.64        14\n",
      "      Neutro       0.47      0.80      0.59        10\n",
      "\n",
      "    accuracy                           0.57        28\n",
      "   macro avg       0.56      0.52      0.50        28\n",
      "weighted avg       0.65      0.57      0.57        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipo=['Positivo', 'Negativo', 'Neutro']\n",
    "print(metrics.classification_report(classes,opniao,tipo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         | N   P |\n",
      "         | e   o |\n",
      "         | g N s |\n",
      "         | a e i |\n",
      "         | t u t |\n",
      "         | i t i |\n",
      "         | v r v |\n",
      "         | o o o |\n",
      "---------+-------+\n",
      "Negativo |<7>6 1 |\n",
      "  Neutro | 1<8>1 |\n",
      "Positivo | . 3<1>|\n",
      "---------+-------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado = []\n",
    "previsto = []\n",
    "for opniao in opniao:\n",
    "    previsto.append(opniao)\n",
    "for classe in classes:\n",
    "    esperado.append(classe)    \n",
    "\n",
    "matriz = ConfusionMatrix(esperado, previsto)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuscaOpiniao(frase):\n",
    "    tweetsprocessados = Preprocessamento(frase)\n",
    "    tweetsprocessadossteaming = SteamingSemStopWords(tweetsprocessados)\n",
    "    freq_tweets = vectorizer.transform(tweetsprocessadossteaming)\n",
    "    opniao = modelo.predict(freq_tweets)\n",
    "    prob = modelo.predict_proba(freq_tweets).max()\n",
    "    return opniao,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutro\n"
     ]
    }
   ],
   "source": [
    "opiniao = BuscaOpiniao([dataset2['Text'][0]])\n",
    "print(opiniao[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = pd.read_csv('Dados2.csv', encoding='ISO-8859-1', delimiter=';')\n",
    "datasetClassificado = pd.DataFrame(columns=['Text','Opiniao','Probabilidade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in dataset3['Text']:\n",
    "    global opiniao\n",
    "    opiniao = BuscaOpiniao([text])\n",
    "    datasetClassificado = datasetClassificado.append({'Text':text,'Opiniao':opiniao[0][0],'Probabilidade':opiniao[1]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetClassificado.to_excel('DadosClassificadosB.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
